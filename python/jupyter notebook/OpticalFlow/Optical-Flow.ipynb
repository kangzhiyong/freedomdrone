{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Flow\n",
    "\n",
    "In this notebook you'll use *Optical Flow* to track features produced by *Shi-Tomasi*, predicting where the features will be in the next frame. This difference in pixel location is the velocity measured in pixels/frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 12, 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to *Shi-Tomasi*, the *Optical Flow* algorithm has many tunable paramters. We'll be using [cv.calcOpticalFlowPyrLK](https://docs.opencv.org/3.4.1/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323) which uses the *Lucas-Kanade* method. Once again, there are several parameters to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Shi Tamasi features\n",
    "feature_params = dict(maxCorners=0,  # no limit on number of corners\n",
    "                      qualityLevel=0.05,\n",
    "                      minDistance=50,\n",
    "                      blockSize=7)\n",
    "\n",
    "# Parameters for Lucas Kanade optical flow\n",
    "optical_flow_params = dict(winSize=(21, 21),\n",
    "                           maxLevel=3, \n",
    "                           criteria=(10, 30, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to shorten the loop in `track` while you're fiddling with the parameters since it'll shorten the time to create the video, and hence the development time. Also note the `detect_interval` argument, by default corners are redetected on every 5th frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shi_tomasi(img):\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    return cv.goodFeaturesToTrack(gray, **feature_params)\n",
    "\n",
    "\n",
    "def optical_flow(frame0, frame1, corners0):        \n",
    "    # convert images to grayscale\n",
    "    frame0_gray = cv.cvtColor(frame0, cv.COLOR_BGR2GRAY)\n",
    "    frame1_gray = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # TODO: Use the Lucas-Kanade method `cv.calcOpticalFlowPyrLK` for Optical Flow\n",
    "    # Indices of the `status` array which equal 1 signify a corresponding new feature has been found\n",
    "    corners1, status, err = cv.calcOpticalFlowPyrLK(frame0_gray, frame1_gray, **optical_flow_params)\n",
    "    \n",
    "    return corners1, status==1\n",
    "    \n",
    "\n",
    "def track(reader, detect_interval=5):\n",
    "    frames = []\n",
    "    \n",
    "    frame0 = reader.get_data(0)\n",
    "    \n",
    "    # Initial corners, after this we'll detect\n",
    "    # corners on the interval `detect_interval`\n",
    "    corners0 = shi_tomasi(frame0)\n",
    "    \n",
    "    mean_u = 0\n",
    "    mean_v = 0\n",
    "    \n",
    "    # Used for weighted average update of the velocity\n",
    "    alpha = 0.97\n",
    "        \n",
    "    # NOTE: You may want to limit this for loop\n",
    "    # to a shorter range at first.\n",
    "    for i in range(1, reader.get_length()):\n",
    "        frame1 = reader.get_data(i)\n",
    "        # for visualization\n",
    "        vis = frame1.copy()         \n",
    "        \n",
    "        corners1, valid = optical_flow(frame0, frame1, corners0)\n",
    "        \n",
    "        # This discards any pixels from `corners0` which did not\n",
    "        # produce a corresponding pixel with optical flow\n",
    "        velocity = ((corners1 - corners0)[valid==1]).reshape(-1, 2)\n",
    "        \n",
    "        # TODO: calculate mean velocity in pixels/frame\n",
    "        u, v = cv.goodFeaturesToTrack(frame1, **feature_params)\n",
    "        \n",
    "        # NOTE: we use a simple weighted average method\n",
    "        # but you may want to use some of the\n",
    "        # estimation techniques you've learned.\n",
    "        mean_u = alpha * mean_u + (1-alpha) * np.mean(u)\n",
    "        mean_v = alpha * mean_v + (1-alpha) * np.mean(v)\n",
    "        \n",
    "        # Velocity related visuals\n",
    "        cv.putText(vis, \"Mean X Velocity (U) = {0:.2f}\".format(mean_u), \n",
    "                   (20, 20), cv.FONT_HERSHEY_PLAIN, 1.0, (255, 255, 255), thickness=2, lineType=cv.LINE_AA)\n",
    "        cv.putText(vis, \"Mean Y Velocity (V) = {0:.2f}\".format(mean_v), \n",
    "                   (20, 35), cv.FONT_HERSHEY_PLAIN, 1.0, (255, 255, 255), thickness=2, lineType=cv.LINE_AA)\n",
    "        vis = cv.arrowedLine(vis, (50, 100), (int(50+5*mean_u), int(100-5*mean_v)), \n",
    "                             (0, 255, 0), 2, tipLength=0.3, line_type=cv.LINE_AA)\n",
    "\n",
    "        # carry over new corners\n",
    "        corners0 = corners1\n",
    "        \n",
    "        # refresh corners\n",
    "        # If we only relied on corners carrying over\n",
    "        # we would eventually run out of corners\n",
    "        if i % detect_interval == 0:\n",
    "            corners0 = shi_tomasi(frame0)\n",
    "    \n",
    "        frame0 = frame1\n",
    "        frames.append(vis)\n",
    "        \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = imageio.get_reader('vid.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'prevPts' (pos 3) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d526de723978>\u001b[0m in \u001b[0;36mtrack\u001b[0;34m(reader, detect_interval)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mvis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mcorners1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptical_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorners0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# This discards any pixels from `corners0` which did not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d526de723978>\u001b[0m in \u001b[0;36moptical_flow\u001b[0;34m(frame0, frame1, corners0)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# TODO: Use the Lucas-Kanade method `cv.calcOpticalFlowPyrLK` for Optical Flow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Indices of the `status` array which equal 1 signify a corresponding new feature has been found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcorners1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcOpticalFlowPyrLK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe0_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe1_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptical_flow_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorners1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Required argument 'prevPts' (pos 3) not found"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1b9efe86a5f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'frames = track(reader, detect_interval=5)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'frames' is not defined"
     ]
    }
   ],
   "source": [
    "%time frames = track(reader, detect_interval=5)\n",
    "print(len(frames), frames[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = ImageSequenceClip(frames, fps=24)\n",
    "clip.ipython_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Solution](./Optical-Flow-Solution.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
